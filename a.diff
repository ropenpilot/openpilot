diff --git a/ws/SConscript b/ws/SConscript
new file mode 100644
index 0000000000000..b0d7d5e64b639
--- /dev/null
+++ b/ws/SConscript
@@ -0,0 +1,12 @@
+import os
+Import('env', 'qt_env', 'arch', 'common', 'messaging', 'visionipc',
+       'cereal', 'transformations')
+
+base_frameworks = qt_env['FRAMEWORKS']
+base_libs = [common, messaging, cereal, visionipc, transformations, 'zmq',
+             'capnp', 'kj', 'm', 'ssl', 'crypto', 'pthread'] + qt_env["LIBS"]
+
+qt_libs = ['qt_util'] + base_libs
+replay_libs = qt_libs
+qt_env.Program("ws", ["ws.cc", "main.cc"], LIBS=replay_libs, FRAMEWORKS=base_frameworks)
+
diff --git a/ws/main.cc b/ws/main.cc
new file mode 100644
index 0000000000000..5be15b7a7377d
--- /dev/null
+++ b/ws/main.cc
@@ -0,0 +1,55 @@
+#include <QApplication>
+#include <QCommandLineParser>
+
+int main(int argc, char *argv[]) {
+  QCoreApplication app(argc, argv);
+
+  const std::tuple<QString, REPLAY_FLAGS, QString> flags[] = {
+      {"dcam", REPLAY_FLAG_DCAM, "load driver camera"},
+      {"ecam", REPLAY_FLAG_ECAM, "load wide road camera"},
+      {"no-loop", REPLAY_FLAG_NO_LOOP, "stop at the end of the route"},
+      {"no-cache", REPLAY_FLAG_NO_FILE_CACHE, "turn off local cache"},
+      {"qcam", REPLAY_FLAG_QCAMERA, "load qcamera"},
+      {"no-hw-decoder", REPLAY_FLAG_NO_HW_DECODER, "disable HW video decoding"},
+      {"no-vipc", REPLAY_FLAG_NO_VIPC, "do not output video"},
+  };
+
+  QCommandLineParser parser;
+  parser.setApplicationDescription("Mock openpilot components by publishing logged messages.");
+  parser.addHelpOption();
+  parser.addPositionalArgument("route", "the drive to replay. find your drives at connect.comma.ai");
+  parser.addOption({{"a", "allow"}, "whitelist of services to send", "allow"});
+  parser.addOption({{"b", "block"}, "blacklist of services to send", "block"});
+  parser.addOption({{"s", "start"}, "start from <seconds>", "seconds"});
+  parser.addOption({"demo", "use a demo route instead of providing your own"});
+  parser.addOption({"data_dir", "local directory with routes", "data_dir"});
+  for (auto &[name, _, desc] : flags) {
+    parser.addOption({name, desc});
+  }
+
+  parser.process(app);
+  const QStringList args = parser.positionalArguments();
+  if (args.empty() && !parser.isSet("demo")) {
+    parser.showHelp();
+  }
+
+  //const QString route = args.empty() ? DEMO_ROUTE : args.first();
+  //QStringList allow = parser.value("allow").isEmpty() ? QStringList{} : parser.value("allow").split(",");
+  //QStringList block = parser.value("block").isEmpty() ? QStringList{} : parser.value("block").split(",");
+
+  //uint32_t replay_flags = REPLAY_FLAG_NONE;
+  //for (const auto &[name, flag, _] : flags) {
+  //  if (parser.isSet(name)) {
+  //    replay_flags |= flag;
+  //  }
+  //}
+  //Replay *replay = new Replay(route, allow, block, nullptr, replay_flags, parser.value("data_dir"), &app);
+  //if (!replay->load()) {
+  //  return 0;
+  //}
+
+  //ConsoleUI console_ui(replay);
+  //replay->start(parser.value("start").toInt());
+  return app.exec();
+  return 0;
+}
diff --git a/ws/ws.cc b/ws/ws.cc
new file mode 100644
index 0000000000000..3d89e8f6fa6c3
--- /dev/null
+++ b/ws/ws.cc
@@ -0,0 +1,431 @@
+//#include "ws/ws.h"
+//
+//#include <QDebug>
+//#include <QtConcurrent>
+//
+//#include <capnp/dynamic.h>
+//#include "cereal/services.h"
+//#include "common/params.h"
+//#include "common/timing.h"
+//#include "system/hardware/hw.h"
+//#include "tools/replay/util.h"
+//
+//Replay::Replay(QString route, QStringList allow, QStringList block, SubMaster *sm_, uint32_t flags, QString data_dir, QObject *parent)
+//    : sm(sm_), flags_(flags), QObject(parent) {
+//  std::vector<const char *> s;
+//  auto event_struct = capnp::Schema::from<cereal::Event>().asStruct();
+//  sockets_.resize(event_struct.getUnionFields().size());
+//  for (const auto &it : services) {
+//    if ((allow.empty() || allow.contains(it.name)) && !block.contains(it.name)) {
+//      uint16_t which = event_struct.getFieldByName(it.name).getProto().getDiscriminantValue();
+//      sockets_[which] = it.name;
+//      if (!allow.empty() || !block.empty()) {
+//        allow_list.insert((cereal::Event::Which)which);
+//      }
+//      s.push_back(it.name);
+//    }
+//  }
+//  qDebug() << "services " << s;
+//  qDebug() << "loading route " << route;
+//
+//  if (sm == nullptr) {
+//    pm = std::make_unique<PubMaster>(s);
+//  }
+//  route_ = std::make_unique<Route>(route, data_dir);
+//  events_ = std::make_unique<std::vector<Event *>>();
+//  new_events_ = std::make_unique<std::vector<Event *>>();
+//}
+//
+//Replay::~Replay() {
+//  stop();
+//}
+//
+//void Replay::stop() {
+//  if (!stream_thread_ && segments_.empty()) return;
+//
+//  rInfo("shutdown: in progress...");
+//  if (stream_thread_ != nullptr) {
+//    exit_ = updating_events_ = true;
+//    stream_cv_.notify_one();
+//    stream_thread_->quit();
+//    stream_thread_->wait();
+//    stream_thread_ = nullptr;
+//  }
+//  segments_.clear();
+//  camera_server_.reset(nullptr);
+//  timeline_future.waitForFinished();
+//  rInfo("shutdown: done");
+//}
+//
+//bool Replay::load() {
+//  if (!route_->load()) {
+//    qCritical() << "failed to load route" << route_->name()
+//                << "from" << (route_->dir().isEmpty() ? "server" : route_->dir());
+//    return false;
+//  }
+//
+//  for (auto &[n, f] : route_->segments()) {
+//    bool has_log = !f.rlog.isEmpty() || !f.qlog.isEmpty();
+//    bool has_video = !f.road_cam.isEmpty() || !f.qcamera.isEmpty();
+//    if (has_log && (has_video || hasFlag(REPLAY_FLAG_NO_VIPC))) {
+//      segments_.insert({n, nullptr});
+//    }
+//  }
+//  if (segments_.empty()) {
+//    qCritical() << "no valid segments in route" << route_->name();
+//    return false;
+//  }
+//  rInfo("load route %s with %zu valid segments", qPrintable(route_->name()), segments_.size());
+//  return true;
+//}
+//
+//void Replay::start(int seconds) {
+//  seekTo(route_->identifier().segment_id * 60 + seconds, false);
+//}
+//
+//void Replay::updateEvents(const std::function<bool()> &lambda) {
+//  // set updating_events to true to force stream thread release the lock and wait for evnets_udpated.
+//  updating_events_ = true;
+//  {
+//    std::unique_lock lk(stream_lock_);
+//    events_updated_ = lambda();
+//    updating_events_ = false;
+//  }
+//  stream_cv_.notify_one();
+//}
+//
+//void Replay::seekTo(double seconds, bool relative) {
+//  seconds = relative ? seconds + currentSeconds() : seconds;
+//  updateEvents([&]() {
+//    seconds = std::max(double(0.0), seconds);
+//    int seg = (int)seconds / 60;
+//    if (segments_.find(seg) == segments_.end()) {
+//      rWarning("can't seek to %d s segment %d is invalid", seconds, seg);
+//      return true;
+//    }
+//
+//    rInfo("seeking to %d s, segment %d", (int)seconds, seg);
+//    current_segment_ = seg;
+//    cur_mono_time_ = route_start_ts_ + seconds * 1e9;
+//    return isSegmentMerged(seg);
+//  });
+//  queueSegment();
+//}
+//
+//void Replay::seekToFlag(FindFlag flag) {
+//  if (auto next = find(flag)) {
+//    seekTo(*next - 2, false);  // seek to 2 seconds before next
+//  }
+//}
+//
+//void Replay::buildTimeline() {
+//  uint64_t engaged_begin = 0;
+//  uint64_t alert_begin = 0;
+//  TimelineType alert_type = TimelineType::None;
+//
+//  for (int i = 0; i < segments_.size() && !exit_; ++i) {
+//    LogReader log;
+//    if (!log.load(route_->at(i).qlog.toStdString(), &exit_,
+//                  {cereal::Event::Which::CONTROLS_STATE, cereal::Event::Which::USER_FLAG},
+//                  !hasFlag(REPLAY_FLAG_NO_FILE_CACHE), 0, 3)) continue;
+//
+//    for (const Event *e : log.events) {
+//      if (e->which == cereal::Event::Which::CONTROLS_STATE) {
+//        auto cs = e->event.getControlsState();
+//
+//        if (!engaged_begin && cs.getEnabled()) {
+//          engaged_begin = e->mono_time;
+//        } else if (engaged_begin && !cs.getEnabled()) {
+//          std::lock_guard lk(timeline_lock);
+//          timeline.push_back({toSeconds(engaged_begin), toSeconds(e->mono_time), TimelineType::Engaged});
+//          engaged_begin = 0;
+//        }
+//
+//        if (!alert_begin && cs.getAlertType().size() > 0) {
+//          alert_begin = e->mono_time;
+//          alert_type = TimelineType::AlertInfo;
+//          if (cs.getAlertStatus() != cereal::ControlsState::AlertStatus::NORMAL) {
+//            alert_type = cs.getAlertStatus() == cereal::ControlsState::AlertStatus::USER_PROMPT
+//                             ? TimelineType::AlertWarning
+//                             : TimelineType::AlertCritical;
+//          }
+//        } else if (alert_begin && cs.getAlertType().size() == 0) {
+//          std::lock_guard lk(timeline_lock);
+//          timeline.push_back({toSeconds(alert_begin), toSeconds(e->mono_time), alert_type});
+//          alert_begin = 0;
+//        }
+//      } else if (e->which == cereal::Event::Which::USER_FLAG) {
+//        std::lock_guard lk(timeline_lock);
+//        timeline.push_back({toSeconds(e->mono_time), toSeconds(e->mono_time), TimelineType::UserFlag});
+//      }
+//    }
+//  }
+//}
+//
+//std::optional<uint64_t> Replay::find(FindFlag flag) {
+//  int cur_ts = currentSeconds();
+//  for (auto [start_ts, end_ts, type] : getTimeline()) {
+//    if (type == TimelineType::Engaged) {
+//      if (flag == FindFlag::nextEngagement && start_ts > cur_ts) {
+//        return start_ts;
+//      } else if (flag == FindFlag::nextDisEngagement && end_ts > cur_ts) {
+//        return end_ts;
+//      }
+//    } else if (start_ts > cur_ts) {
+//      if ((flag == FindFlag::nextUserFlag && type == TimelineType::UserFlag) ||
+//          (flag == FindFlag::nextInfo && type == TimelineType::AlertInfo) ||
+//          (flag == FindFlag::nextWarning && type == TimelineType::AlertWarning) ||
+//          (flag == FindFlag::nextCritical && type == TimelineType::AlertCritical)) {
+//        return start_ts;
+//      }
+//    }
+//  }
+//  return std::nullopt;
+//}
+//
+//void Replay::pause(bool pause) {
+//  updateEvents([=]() {
+//    rWarning("%s at %d s", pause ? "paused..." : "resuming", currentSeconds());
+//    paused_ = pause;
+//    return true;
+//  });
+//}
+//
+//void Replay::setCurrentSegment(int n) {
+//  if (current_segment_.exchange(n) != n) {
+//    QMetaObject::invokeMethod(this, &Replay::queueSegment, Qt::QueuedConnection);
+//  }
+//}
+//
+//void Replay::segmentLoadFinished(bool success) {
+//  if (!success) {
+//    Segment *seg = qobject_cast<Segment *>(sender());
+//    rWarning("failed to load segment %d, removing it from current replay list", seg->seg_num);
+//    segments_.erase(seg->seg_num);
+//  }
+//  queueSegment();
+//}
+//
+//void Replay::queueSegment() {
+//  if (segments_.empty()) return;
+//
+//  SegmentMap::iterator cur, end;
+//  cur = end = segments_.lower_bound(std::min(current_segment_.load(), segments_.rbegin()->first));
+//  for (int i = 0; end != segments_.end() && i <= FORWARD_SEGS; ++i) {
+//    ++end;
+//  }
+//  // load one segment at a time
+//  for (auto it = cur; it != end; ++it) {
+//    auto &[n, seg] = *it;
+//    if ((seg && !seg->isLoaded()) || !seg) {
+//      if (!seg) {
+//        rDebug("loading segment %d...", n);
+//        seg = std::make_unique<Segment>(n, route_->at(n), flags_, allow_list);
+//        QObject::connect(seg.get(), &Segment::loadFinished, this, &Replay::segmentLoadFinished);
+//      }
+//      break;
+//    }
+//  }
+//
+//  const auto &cur_segment = cur->second;
+//  // merge the previous adjacent segment if it's loaded
+//  auto begin = segments_.find(cur_segment->seg_num - 1);
+//  if (begin == segments_.end() || !(begin->second && begin->second->isLoaded())) {
+//    begin = cur;
+//  }
+//  mergeSegments(begin, end);
+//
+//  // free segments out of current semgnt window.
+//  std::for_each(segments_.begin(), begin, [](auto &e) { e.second.reset(nullptr); });
+//  std::for_each(end, segments_.end(), [](auto &e) { e.second.reset(nullptr); });
+//
+//  // start stream thread
+//  if (stream_thread_ == nullptr && cur_segment->isLoaded()) {
+//    startStream(cur_segment.get());
+//    emit streamStarted();
+//  }
+//}
+//
+//void Replay::mergeSegments(const SegmentMap::iterator &begin, const SegmentMap::iterator &end) {
+//  // merge 3 segments in sequence.
+//  std::vector<int> segments_need_merge;
+//  size_t new_events_size = 0;
+//  for (auto it = begin; it != end && it->second && it->second->isLoaded() && segments_need_merge.size() < 3; ++it) {
+//    segments_need_merge.push_back(it->first);
+//    new_events_size += it->second->log->events.size();
+//  }
+//
+//  if (segments_need_merge != segments_merged_) {
+//    std::string s;
+//    for (int i = 0; i < segments_need_merge.size(); ++i) {
+//      s += std::to_string(segments_need_merge[i]);
+//      if (i != segments_need_merge.size() - 1) s += ", ";
+//    }
+//    rDebug("merge segments %s", s.c_str());
+//    new_events_->clear();
+//    new_events_->reserve(new_events_size);
+//    for (int n : segments_need_merge) {
+//      const auto &e = segments_[n]->log->events;
+//      auto middle = new_events_->insert(new_events_->end(), e.begin(), e.end());
+//      std::inplace_merge(new_events_->begin(), middle, new_events_->end(), Event::lessThan());
+//    }
+//
+//    updateEvents([&]() {
+//      events_.swap(new_events_);
+//      segments_merged_ = segments_need_merge;
+//      return true;
+//    });
+//    if (stream_thread_) {
+//      emit segmentsMerged();
+//    }
+//  }
+//}
+//
+//void Replay::startStream(const Segment *cur_segment) {
+//  const auto &events = cur_segment->log->events;
+//
+//  // get route start time from initData
+//  auto it = std::find_if(events.begin(), events.end(), [](auto e) { return e->which == cereal::Event::Which::INIT_DATA; });
+//  route_start_ts_ = it != events.end() ? (*it)->mono_time : events[0]->mono_time;
+//  cur_mono_time_ += route_start_ts_;
+//
+//  // write CarParams
+//  it = std::find_if(events.begin(), events.end(), [](auto e) { return e->which == cereal::Event::Which::CAR_PARAMS; });
+//  if (it != events.end()) {
+//    car_fingerprint_ = (*it)->event.getCarParams().getCarFingerprint();
+//    capnp::MallocMessageBuilder builder;
+//    builder.setRoot((*it)->event.getCarParams());
+//    auto words = capnp::messageToFlatArray(builder);
+//    auto bytes = words.asBytes();
+//    Params().put("CarParams", (const char *)bytes.begin(), bytes.size());
+//    Params().put("CarParamsPersistent", (const char *)bytes.begin(), bytes.size());
+//  } else {
+//    rWarning("failed to read CarParams from current segment");
+//  }
+//
+//  // start camera server
+//  if (!hasFlag(REPLAY_FLAG_NO_VIPC)) {
+//    std::pair<int, int> camera_size[MAX_CAMERAS] = {};
+//    for (auto type : ALL_CAMERAS) {
+//      if (auto &fr = cur_segment->frames[type]) {
+//        camera_size[type] = {fr->width, fr->height};
+//      }
+//    }
+//    camera_server_ = std::make_unique<CameraServer>(camera_size);
+//  }
+//
+//  emit segmentsMerged();
+//  // start stream thread
+//  stream_thread_ = new QThread();
+//  QObject::connect(stream_thread_, &QThread::started, [=]() { stream(); });
+//  QObject::connect(stream_thread_, &QThread::finished, stream_thread_, &QThread::deleteLater);
+//  stream_thread_->start();
+//
+//  timeline_future = QtConcurrent::run(this, &Replay::buildTimeline);
+//}
+//
+//void Replay::publishMessage(const Event *e) {
+//  if (event_filter && event_filter(e, filter_opaque)) return;
+//
+//  if (sm == nullptr) {
+//    auto bytes = e->bytes();
+//    int ret = pm->send(sockets_[e->which], (capnp::byte *)bytes.begin(), bytes.size());
+//    if (ret == -1) {
+//      rWarning("stop publishing %s due to multiple publishers error", sockets_[e->which]);
+//      sockets_[e->which] = nullptr;
+//    }
+//  } else {
+//    sm->update_msgs(nanos_since_boot(), {{sockets_[e->which], e->event}});
+//  }
+//}
+//
+//void Replay::publishFrame(const Event *e) {
+//  static const std::map<cereal::Event::Which, CameraType> cam_types{
+//      {cereal::Event::ROAD_ENCODE_IDX, RoadCam},
+//      {cereal::Event::DRIVER_ENCODE_IDX, DriverCam},
+//      {cereal::Event::WIDE_ROAD_ENCODE_IDX, WideRoadCam},
+//  };
+//  if ((e->which == cereal::Event::DRIVER_ENCODE_IDX && !hasFlag(REPLAY_FLAG_DCAM)) ||
+//      (e->which == cereal::Event::WIDE_ROAD_ENCODE_IDX && !hasFlag(REPLAY_FLAG_ECAM))) {
+//    return;
+//  }
+//  auto eidx = capnp::AnyStruct::Reader(e->event).getPointerSection()[0].getAs<cereal::EncodeIndex>();
+//  if (eidx.getType() == cereal::EncodeIndex::Type::FULL_H_E_V_C && isSegmentMerged(eidx.getSegmentNum())) {
+//    CameraType cam = cam_types.at(e->which);
+//    camera_server_->pushFrame(cam, segments_[eidx.getSegmentNum()]->frames[cam].get(), eidx);
+//  }
+//}
+//
+//void Replay::stream() {
+//  cereal::Event::Which cur_which = cereal::Event::Which::INIT_DATA;
+//  std::unique_lock lk(stream_lock_);
+//
+//  while (true) {
+//    stream_cv_.wait(lk, [=]() { return exit_ || (events_updated_ && !paused_); });
+//    events_updated_ = false;
+//    if (exit_) break;
+//
+//    Event cur_event(cur_which, cur_mono_time_);
+//    auto eit = std::upper_bound(events_->begin(), events_->end(), &cur_event, Event::lessThan());
+//    if (eit == events_->end()) {
+//      rInfo("waiting for events...");
+//      continue;
+//    }
+//
+//    uint64_t evt_start_ts = cur_mono_time_;
+//    uint64_t loop_start_ts = nanos_since_boot();
+//
+//    for (auto end = events_->end(); !updating_events_ && eit != end; ++eit) {
+//      const Event *evt = (*eit);
+//      cur_which = evt->which;
+//      cur_mono_time_ = evt->mono_time;
+//      setCurrentSegment(toSeconds(cur_mono_time_) / 60);
+//
+//      // migration for pandaState -> pandaStates to keep UI working for old segments
+//      if (cur_which == cereal::Event::Which::PANDA_STATE_D_E_P_R_E_C_A_T_E_D &&
+//          sockets_[cereal::Event::Which::PANDA_STATES] != nullptr) {
+//        MessageBuilder msg;
+//        auto ps = msg.initEvent().initPandaStates(1);
+//        ps[0].setIgnitionLine(true);
+//        ps[0].setPandaType(cereal::PandaState::PandaType::DOS);
+//        pm->send(sockets_[cereal::Event::Which::PANDA_STATES], msg);
+//      }
+//
+//      if (cur_which < sockets_.size() && sockets_[cur_which] != nullptr) {
+//        // keep time
+//        long etime = (cur_mono_time_ - evt_start_ts) / speed_;
+//        long rtime = nanos_since_boot() - loop_start_ts;
+//        long behind_ns = etime - rtime;
+//        // if behind_ns is greater than 1 second, it means that an invalid segemnt is skipped by seeking/replaying
+//        if (behind_ns >= 1 * 1e9) {
+//          // reset start times
+//          evt_start_ts = cur_mono_time_;
+//          loop_start_ts = nanos_since_boot();
+//        } else if (behind_ns > 0 && !hasFlag(REPLAY_FLAG_FULL_SPEED)) {
+//          precise_nano_sleep(behind_ns);
+//        }
+//
+//        if (!evt->frame) {
+//          publishMessage(evt);
+//        } else if (camera_server_) {
+//          if (hasFlag(REPLAY_FLAG_FULL_SPEED)) {
+//            camera_server_->waitForSent();
+//          }
+//          publishFrame(evt);
+//        }
+//      }
+//    }
+//    // wait for frame to be sent before unlock.(frameReader may be deleted after unlock)
+//    if (camera_server_) {
+//      camera_server_->waitForSent();
+//    }
+//
+//    if (eit == events_->end() && !hasFlag(REPLAY_FLAG_NO_LOOP)) {
+//      int last_segment = segments_.rbegin()->first;
+//      if (current_segment_ >= last_segment && isSegmentMerged(last_segment)) {
+//        rInfo("reaches the end of route, restart from beginning");
+//        QMetaObject::invokeMethod(this, std::bind(&Replay::seekTo, this, 0, false), Qt::QueuedConnection);
+//      }
+//    }
+//  }
+//}
diff --git a/ws/ws.h b/ws/ws.h
new file mode 100644
index 0000000000000..a3881547abd5c
--- /dev/null
+++ b/ws/ws.h
@@ -0,0 +1,132 @@
+#pragma once
+//
+//#include <optional>
+//
+//#include <QThread>
+//
+//#include "tools/replay/camera.h"
+//#include "tools/replay/route.h"
+//
+//// one segment uses about 100M of memory
+//constexpr int FORWARD_SEGS = 5;
+//
+//enum REPLAY_FLAGS {
+//  REPLAY_FLAG_NONE = 0x0000,
+//  REPLAY_FLAG_DCAM = 0x0002,
+//  REPLAY_FLAG_ECAM = 0x0004,
+//  REPLAY_FLAG_NO_LOOP = 0x0010,
+//  REPLAY_FLAG_NO_FILE_CACHE = 0x0020,
+//  REPLAY_FLAG_QCAMERA = 0x0040,
+//  REPLAY_FLAG_NO_HW_DECODER = 0x0100,
+//  REPLAY_FLAG_FULL_SPEED = 0x0200,
+//  REPLAY_FLAG_NO_VIPC = 0x0400,
+//};
+//
+//enum class FindFlag {
+//  nextEngagement,
+//  nextDisEngagement,
+//  nextUserFlag,
+//  nextInfo,
+//  nextWarning,
+//  nextCritical
+//};
+//
+//enum class TimelineType { None, Engaged, AlertInfo, AlertWarning, AlertCritical, UserFlag };
+//typedef bool (*replayEventFilter)(const Event *, void *);
+//
+//class Replay : public QObject {
+//  Q_OBJECT
+//
+//public:
+//  Replay(QString route, QStringList allow, QStringList block, SubMaster *sm = nullptr,
+//          uint32_t flags = REPLAY_FLAG_NONE, QString data_dir = "", QObject *parent = 0);
+//  ~Replay();
+//  bool load();
+//  void start(int seconds = 0);
+//  void stop();
+//  void pause(bool pause);
+//  void seekToFlag(FindFlag flag);
+//  void seekTo(double seconds, bool relative);
+//  inline bool isPaused() const { return paused_; }
+//  // the filter is called in streaming thread.try to return quickly from it to avoid blocking streaming.
+//  // the filter function must return true if the event should be filtered.
+//  // otherwise it must return false.
+//  inline void installEventFilter(replayEventFilter filter, void *opaque) {
+//    filter_opaque = opaque;
+//    event_filter = filter;
+//  }
+//  inline bool hasFlag(REPLAY_FLAGS flag) const { return flags_ & flag; }
+//  inline void addFlag(REPLAY_FLAGS flag) { flags_ |= flag; }
+//  inline void removeFlag(REPLAY_FLAGS flag) { flags_ &= ~flag; }
+//  inline const Route* route() const { return route_.get(); }
+//  inline double currentSeconds() const { return double(cur_mono_time_ - route_start_ts_) / 1e9; }
+//  inline uint64_t routeStartTime() const { return route_start_ts_; }
+//  inline int toSeconds(uint64_t mono_time) const { return (mono_time - route_start_ts_) / 1e9; }
+//  inline int totalSeconds() const { return segments_.size() * 60; }
+//  inline void setSpeed(float speed) { speed_ = speed; }
+//  inline float getSpeed() const { return speed_; }
+//  inline const std::vector<Event *> *events() const { return events_.get(); }
+//  inline const std::string &carFingerprint() const { return car_fingerprint_; }
+//  inline const std::vector<std::tuple<int, int, TimelineType>> getTimeline() {
+//    std::lock_guard lk(timeline_lock);
+//    return timeline;
+//  }
+//
+//signals:
+//  void streamStarted();
+//  void segmentsMerged();
+//
+//protected slots:
+//  void segmentLoadFinished(bool success);
+//
+//protected:
+//  typedef std::map<int, std::unique_ptr<Segment>> SegmentMap;
+//  std::optional<uint64_t> find(FindFlag flag);
+//  void startStream(const Segment *cur_segment);
+//  void stream();
+//  void setCurrentSegment(int n);
+//  void queueSegment();
+//  void mergeSegments(const SegmentMap::iterator &begin, const SegmentMap::iterator &end);
+//  void updateEvents(const std::function<bool()>& lambda);
+//  void publishMessage(const Event *e);
+//  void publishFrame(const Event *e);
+//  void buildTimeline();
+//  inline bool isSegmentMerged(int n) {
+//    return std::find(segments_merged_.begin(), segments_merged_.end(), n) != segments_merged_.end();
+//  }
+//
+//  QThread *stream_thread_ = nullptr;
+//
+//  // logs
+//  std::mutex stream_lock_;
+//  std::condition_variable stream_cv_;
+//  std::atomic<bool> updating_events_ = false;
+//  std::atomic<int> current_segment_ = 0;
+//  SegmentMap segments_;
+//  // the following variables must be protected with stream_lock_
+//  std::atomic<bool> exit_ = false;
+//  bool paused_ = false;
+//  bool events_updated_ = false;
+//  uint64_t route_start_ts_ = 0;
+//  std::atomic<uint64_t> cur_mono_time_ = 0;
+//  std::unique_ptr<std::vector<Event *>> events_;
+//  std::unique_ptr<std::vector<Event *>> new_events_;
+//  std::vector<int> segments_merged_;
+//
+//  // messaging
+//  SubMaster *sm = nullptr;
+//  std::unique_ptr<PubMaster> pm;
+//  std::vector<const char*> sockets_;
+//  std::unique_ptr<Route> route_;
+//  std::unique_ptr<CameraServer> camera_server_;
+//  std::atomic<uint32_t> flags_ = REPLAY_FLAG_NONE;
+//
+//  std::mutex timeline_lock;
+//  QFuture<void> timeline_future;
+//  std::vector<std::tuple<int, int, TimelineType>> timeline;
+//  std::set<cereal::Event::Which> allow_list;
+//  std::string car_fingerprint_;
+//  float speed_ = 1.0;
+//  replayEventFilter event_filter = nullptr;
+//  void *filter_opaque = nullptr;
+//};
